---
title: "Homework 5"
author: "Yiying Wu"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## 1
Read data
```{r,message=FALSE}
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read_csv(url(urlfile))|>
                  janitor::clean_names()

```

Prepare data
```{r}
homicide_summary=homicide_data|>
  unite("city_state", city, state, sep = ", ") |>
  group_by(city_state) |>
  summarize(
    Total_Homicides = n(),
    Unsolved_Homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")))
```

Proportion test for Baltimore, MD
```{r}
baltimore_data <- filter(homicide_summary, city_state == "Baltimore, MD")
baltimore_test <- prop.test(baltimore_data$Unsolved_Homicides, baltimore_data$Total_Homicides)
baltimore_test |> broom::tidy()
```

Proportion test for all cities
```{r,message=FALSE,warning=FALSE}
all_cities_test <- homicide_summary %>%
  mutate(
    test_result = map2(Unsolved_Homicides, Total_Homicides, ~prop.test(.x, .y)),
    tidy_result = map(test_result, broom::tidy),  # Specify broom::tidy directly
    city_state = city_state  # Preserve city_state in the final result
  ) %>%
  select(-test_result) %>%  # Remove the test_result column
  unnest(tidy_result)

all_cities_test=all_cities_test|>select(city_state, estimate, conf.low, conf.high)
all_cities_test
```

Create a plot that shows the estimates and CIs for each city
```{r, fig.width = 10}
ggplot(all_cities_test, aes(x=reorder(city_state, estimate), y=estimate)) +
  geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), width=.2) +
  coord_flip() +
  xlab("City, State") +
  ylab("Proportion of Unsolved Homicides") +
  ggtitle("Proportion of Unsolved Homicides in Various Cities")
```

## 2
import data
```{r}
data_files = tibble(list.files("./data")) |>
  mutate(file_list = paste(list.files("./data")))
```
Creating functions to read multiple datasets in the list
```{r,message=FALSE}
read_files = function(x) {
  
    data = read_csv(paste0("./data/", x))|>
      mutate(file_names = x)
}

arm_dataset = map_df(data_files$file_list, read_files)

arm_dataset
```
Tidy the dataset
```{r}
clean_arm_dataset =
  arm_dataset |>
  janitor::clean_names() |>
  gather(key = week, value = arm_value, week_1:week_8) |>
  mutate(week = str_remove(week, "week_")) |>
  mutate(subject_ID = as.integer(str_extract(file_names, "[0-9][0-9]"))) |>
  mutate(file_names = ifelse(str_detect(file_names, "con") == TRUE,
                             "Control", "Experiment")) |>
  mutate(across(.cols = c(file_names, week, subject_ID), as.factor)) |>
  relocate(file_names, subject_ID, arm_value)

clean_arm_dataset
```

spaghetti plot showing observations on each subject over time
```{r}
clean_arm_dataset |>
  ggplot(aes(week, arm_value, color=subject_ID)) + 
  geom_point(size = 0.2) + 
  geom_line(aes(group = subject_ID), alpha=0.5) +
  facet_grid(~file_names) +
  labs(x = "Week", y = "Arm Value", 
       title = "Arm Values on Each Subject over 8 Weeks in Two Groups",
       col = "Subject ID") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

In the experimental group, subjects generally experienced an increase in arm measurements over the 8-week period, although the timing and extent of these changes varied among individuals. Conversely, in the control group, subjects' arm measurements fluctuated over time without any clear trend or significant alterations, in contrast to those in the experimental group. Notably, no individuals in the control group achieved arm measurements exceeding 5, whereas approximately half of the participants in the experimental group surpassed this value during the study.

## 3
Generate 5000 datasets from the model
$$x\sim Normal[\mu,\sigma]$$
```{r}
set.seed(8105) # For reproducibility
n = 30 # Sample size
sigma = 5 # Standard deviation
mu_values = 0:6 # True mean values
alpha = 0.05 # Significance level
num_simulations = 5000 # Number of simulations

simulation_results = map_dfr(mu_values, function(mu) {
  tibble(
    mu = mu,
    simulation = map(1:num_simulations, ~ t.test(rnorm(n, mu, sigma))),
    estimate = map_dbl(simulation, ~ broom::tidy(.x)$estimate),
    p_value = map_dbl(simulation, ~ broom::tidy(.x)$p.value),
    reject_null = p_value < alpha
  )
})
```

Plot: Proportion of times the null is rejected (power of the test)
```{r}
# create power_results dataset
power_results <- simulation_results |>
  group_by(mu) |>
  summarise(power = mean(reject_null), 
            avg_mu_hat = mean(estimate), 
            avg_mu_hat_rejected = mean(estimate[reject_null]))

#plotting
power_plot = power_results |>
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(title = "Power vs. True Mean", x = "True Mean (mu)", y = "Power")

power_plot
```

There's a positive relationship between effect size and power, with diminishing returns as the effect size becomes large. 
As the true mean $\mu$ increases away from 0, the power of the test also increases. The power increases rapidly as $\mu$ moves from 0 to 2, showing a steep curve. The rate of increase in power slows down as $\mu$ becomes larger (around 4 and above). This relationship is consistent with statistical theory: larger effect sizes make it easier to detect a true effect, thus increasing the power of the test.

Plot: Average estimate of mu
```{r}
estimate_plot <- power_results |>
  ggplot(aes(x = mu)) +
  geom_point(aes(y = avg_mu_hat, color = "Average Estimate"), shape = 1) +  
  geom_line(aes(y = avg_mu_hat, color = "Average Estimate")) +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Conditional Average Estimate"), shape = 2) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Conditional Average Estimate"), linetype = "dashed") +
  labs(
    title = "Average Estimated Mean vs. True Mean",
    x = "True Mean (mu)",
    y = "Average Estimated Mean",
    color = "mu_hat"
  ) +
  scale_color_manual(
    values = c("Average Estimate" = "blue", "Conditional Average Estimate" = "red")
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

estimate_plot

```

the sample average of $\hat{\mu}$ across tests for which the null is rejected is not approximately equal to the true value of $\mu$, particularly for smaller true mean values. This is because the rejection of the null hypothesis is partially driven by the magnitude of $\hat{\mu}$, leading to an overestimate of the true mean when the null is rejected. As the true mean increases, the conditional estimates approach the line $\hat\mu=\mu$, since larger true means are easier to detect and less subject to the extremes of sampling variability.